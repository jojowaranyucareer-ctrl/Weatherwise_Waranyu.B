Tool: ChatGPT
Date: 2025-10-12
Topic: Setting up the API and understanding environment variables for Hands-On AI (Ollama connection)

Me: Hi ChatGPT, I’m starting my Weather Advisor Python project, and the instructions say I need to connect it to a Hands-On AI provider called Ollama. I saw some example code using os.environ, but I don’t really understand what it does or why I need it. Can you explain it simply?

AI: Of course! The os.environ object in Python is a dictionary that stores environment variables — values that live outside your code but can be read by your program. Developers often use them to store sensitive information such as API keys, passwords, or URLs so they don’t appear directly in the codebase.

For example:

import os
os.environ['HANDS_ON_AI_SERVER'] = 'https://ollama.serveur.au'
os.environ['HANDS_ON_AI_MODEL'] = 'llama3.2'
os.environ['HANDS_ON_AI_API_KEY'] = 'your_api_key_here'


This means that anytime your script runs, it knows where to send your requests (SERVER), which model to use (MODEL), and what key to authenticate with (API_KEY).

Me: So it’s like setting global variables that the whole program can access?

AI: Exactly — but the main advantage is security and portability. You can move your code between machines (like from your laptop to your friend’s computer or a server) without hard-coding secret data into your script. For instance, you could load them automatically from your system or a .env file so your code stays clean.

Me: I see. But if I don’t use os.environ, can I just define them like normal variables at the top of my script?

AI: You technically can, but it’s not recommended because:

It’s insecure — your API key will be visible to anyone who reads your code.

It’s inflexible — if you later change servers or keys, you’d have to edit your code.

Some libraries automatically look for environment variables (e.g., os.getenv("HANDS_ON_AI_API_KEY")) so skipping them could break compatibility.

Using environment variables is a best practice for software development, especially for cloud or AI integrations.

Me: That makes sense. So where do I get this API key?

AI: You can get it from the Ollama website. Go to https://ollama.com
, sign in, and find API Keys under your account settings. For demo or educational purposes, they often provide a temporary key. You’ll then copy it and assign it to your environment variable.

Example:

import os

os.environ['HANDS_ON_AI_SERVER'] = 'https://ollama.serveur.au'
os.environ['HANDS_ON_AI_MODEL'] = 'llama3.2'
os.environ['HANDS_ON_AI_API_KEY'] = 'e6903b35e08f4227b3a4cbee5b836408'  # demo key


Me: After I set that up, how do I know if it’s working? Like, is there a way to test the connection before I start coding the full project?

AI: Great critical question — yes, you should always test connectivity early!
Here’s a minimal test script:

from hands_on_ai.chat import get_response

print(get_response("Hello AI, are you connected?"))


If the setup works, you’ll get a short response like “Yes, I’m here!”

If you get an error such as “Connection error” or “Invalid API key”, that usually means one of these:

The server URL is wrong (try using https://ollama.serveur.au or the address provided by your instructor)

The API key was typed incorrectly or expired

Your network connection is blocking the request

Me: I actually tried that, and I got a Connection error. It worked fine on my friend’s laptop, but not mine. What could be different?

AI: That’s an insightful observation! If it works elsewhere, the problem is probably local. Possible reasons include:

Firewall or proxy: Your computer or campus Wi-Fi might block outbound HTTPS requests to the server.

Environment variable not set in your current session: Try printing it with print(os.getenv("HANDS_ON_AI_API_KEY")) to confirm it’s loaded.

Python environment mismatch: Maybe you installed hands_on_ai in one virtual environment but are running another. You can check using pip list.

A quick troubleshooting tip:

import os
import requests

print("Server:", os.getenv("HANDS_ON_AI_SERVER"))
print("Key exists:", bool(os.getenv("HANDS_ON_AI_API_KEY")))
try:
    requests.get(os.getenv("HANDS_ON_AI_SERVER"))
    print("✅ Connection to server is available")
except Exception as e:
    print("❌ Connection failed:", e)


This helps you isolate whether it’s a network issue or a missing variable.

Me: That’s helpful. I didn’t realize I could test it step by step like that. What happens if I accidentally upload this file with the API key visible in GitHub or my submission?

AI: Excellent ethical and security concern! If an API key becomes public, anyone can use your account’s resources, potentially costing money or breaking usage limits. That’s why professionals use .env files or secret managers.

A simple solution for class projects is to use the python-dotenv library:

pip install python-dotenv


Then, create a .env file:

HANDS_ON_AI_SERVER=https://ollama.serveur.au
HANDS_ON_AI_MODEL=llama3.2
HANDS_ON_AI_API_KEY=e6903b35e08f4227b3a4cbee5b836408


And load it:

from dotenv import load_dotenv
load_dotenv()


This way, the file stays local and can be excluded from GitHub using .gitignore.

Me: I like that — it feels more professional. So my final setup would be something like this, right?

import os
from hands_on_ai.chat import get_response

os.environ['HANDS_ON_AI_SERVER'] = 'https://ollama.serveur.au'
os.environ['HANDS_ON_AI_MODEL'] = 'llama3.2'
os.environ['HANDS_ON_AI_API_KEY'] = 'e6903b35e08f4227b3a4cbee5b836408'

print(get_response("Can you tell me if the setup is working?"))


AI: Perfect! That’s clean, readable, and fully functional. You now understand:

Why environment variables are used

How to securely store API credentials

How to verify the connection

How to troubleshoot network and environment issues

You can now confidently move to the next phase of your Weather Advisor project — integrating this AI connection into your data retrieval module.
