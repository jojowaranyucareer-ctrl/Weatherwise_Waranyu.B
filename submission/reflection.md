# ðŸªž Project Reflection

---

## ðŸ¤– AI Tools Used

I used **ChatGPT** as my sole AI tool during development. I treated it as a **design partner** â€” clarifying requirements, drafting pseudocode, stress-testing edge cases, and iterating on structure.  

ChatGPTâ€™s biggest value was helping me **think aloud**: I could restate goals, propose a plan, and get immediate feedback before touching code.  

Outside of ChatGPT, the project also relied on several key tools and libraries:
- **OpenWeather REST API** â€“ to retrieve real-time forecast data  
- **ipywidgets** â€“ for building an interactive notebook interface  
- **matplotlib** â€“ for creating temperature and rainfall visualisations  

---

## ðŸ’¬ Prompting Techniques

I applied several **intentional prompting strategies** throughout development:

1. **Restating the problem** in my own words to confirm inputs, outputs, and constraints  
   > Example: â€œ5-day forecast, 3-hour intervals, metric units.â€  
2. **Requesting pseudocode** before implementation to keep each function single-purpose and avoid rewrites.  
3. **Testing edge cases** deliberately â€” such as invalid city names, missing API keys, empty lists, and interpreting â€œtomorrowâ€ from 3-hour intervals.  
4. **Refactoring modularly**, ensuring retrieval, processing, visualisation, and conversation logic were decoupled.  
5. **Asking for line-by-line explanations** of complex code segments (for example, parsing `dt_txt` timestamps) to deepen understanding.  
6. **Iterating deliberately**: propose â†’ implement minimal version â†’ test with real data â†’ refine based on outcomes.

These techniques made my collaboration with ChatGPT structured and goal-oriented, improving both accuracy and learning.

---

## âœ… What Worked Well

The **architecture** is what I am most proud of.  
Separation of concerns kept the system understandable and easy to test.

- `openWeather_getWeather()` focuses on **data retrieval** and **error handling**.  
- **Processing functions** transform raw 3-hour readings into logical daily groupings.  
- **Visualisation functions** are pure consumers of processed data â€” simple to test independently.  
- The **AI conversation layer** turns structured weather data into clear, human-readable responses.

This modular structure made **debugging straightforward**.  
I verified JSON shapes and keys, confirmed grouping logic, tested small (3-day) charts before 5-day ones, and ran full end-to-end tests with realistic user questions.  

Small quality touches enhanced usability, such as:
- **Caching** the last location and dataset for responsiveness.  
- A **temperature-advice helper** that turns numeric data into friendly guidance (â€œItâ€™s warm enough for outdoor exerciseâ€).  

---

## ðŸ”„ What I Would Do Differently

If I had more time, I would focus on **improving natural-language parsing**.  
The current approach uses simple capitalization and keyword heuristics â€” acceptable for a demo but brittle with:
- Multi-word cities (â€œNew Yorkâ€)  
- Ambiguous phrasing  
- Relative date expressions (â€œthe day after tomorrowâ€)

A lightweight **NLP layer** or compact **rules engine** could improve reliability.  

I would also make several structural and performance enhancements:
- Add **response validation and guardrails** in the AI layer:  
  - Unit normalization (Â°C/Â°F)  
  - Consistent rounding  
  - Clear â€œinsufficient dataâ€ messages  
- Implement **short-TTL caching** and **asynchronous I/O** for faster API calls.  
- Introduce **schema validation** (e.g., with *Pydantic*) to detect malformed data early.  
- Expand **unit tests** using mocked payloads for:  
  - Error scenarios  
  - Rate limits  
  - Unexpected API responses  
- Move all configuration to a **`.env` file** and improve setup documentation with a **troubleshooting section** for common network or key errors.

These improvements would make WeatherWise more robust, scalable, and maintainable for real-world use.

---

## ðŸ’­ Final Thoughts

This project reinforced a **productive workflow for collaborating with AI tools**:  
> Restate the goal â†’ Ask for structure â†’ Challenge edge cases â†’ Build the smallest viable version â†’ Test with real data â†’ Refine iteratively.  

ChatGPT served as a **thinking partner**, not just a code generator â€” helping me structure ideas, foresee design challenges, and validate assumptions before coding.  

The result is a **compact, maintainable weather application** that not only presents weather data but also **explains it clearly and conversationally**.  
It demonstrates how AI can enhance software design thinking, accelerate learning, and improve development quality through guided iteration.
